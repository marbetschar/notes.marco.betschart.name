{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees Example 3.1\n",
    "We split the **heart** data set into a training set of 250 items and use the remaining 53 cases as a test set. We predict the outcome of these 53 cases using a decision tree that is grown from the training set and evaluate the prediction result by means of a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n",
      " true        0   1  Sum\n",
      "predicted             \n",
      "0          25   6   31\n",
      "1           5  13   18\n",
      "Sum        30  19   49\n",
      "\n",
      "\n",
      "Train data:\n",
      " true         0    1  Sum\n",
      "predicted               \n",
      "0          131    0  131\n",
      "1            0  119  119\n",
      "Sum        131  119  250\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./data/Heart.csv')\n",
    "\n",
    "# Replace Categorical Variable with dummies\n",
    "df = pd.get_dummies(data=df, columns=['AHD'], drop_first=True)\n",
    "df['ChestPain'], ChestPain_codes = pd.factorize(df['ChestPain'])\n",
    "df['Thal'], Thal_codes = pd.factorize(df['Thal'])\n",
    "# Drop NA rows:\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True) # After removing NA\n",
    "\n",
    "# Split in test-train\n",
    "np.random.seed(0)\n",
    "i = df.index\n",
    "# Index of train\n",
    "i_train = np.random.choice(i, replace=False, size=int(250))\n",
    "\n",
    "# Save DataFrames\n",
    "df_train = df.iloc[i_train]\n",
    "df_test = df.drop(i_train)\n",
    "\n",
    "# Define x and y\n",
    "y_train = df_train['AHD_Yes']\n",
    "y_test = df_test['AHD_Yes']\n",
    "X_train = df_train.drop(columns=['AHD_Yes'])\n",
    "X_test = df_test.drop(columns=['AHD_Yes'])\n",
    "\n",
    "# Create and fit Decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', \n",
    "                                  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_impurity_decrease=0.0001)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions:\n",
    "y_train_pred = clf.predict(X_train).astype(int)\n",
    "y_test_pred = clf.predict(X_test).astype(int)\n",
    "\n",
    "# Create confusion matrix\n",
    "def confusion(y_true, y_pred):\n",
    "    conf = pd.DataFrame({'predicted': y_pred, 'true': y_true})\n",
    "    conf = pd.crosstab(conf.predicted, conf.true, \n",
    "                       margins=True, margins_name=\"Sum\")\n",
    "    return conf\n",
    "\n",
    "print('Test data:\\n', \n",
    "      confusion(y_test.T.to_numpy(), y_test_pred))\n",
    "print('\\n\\nTrain data:\\n', \n",
    "      confusion(y_train.T.to_numpy(), y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error on Testdata:\n",
      " 0.224 \n",
      "Classification error on Traindata:\n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "# Classification error:\n",
    "err_test = abs(y_test - y_test_pred).mean()\n",
    "err_train = abs(y_train - y_train_pred).mean()\n",
    "\n",
    "print('Classification error on Testdata:\\n', np.round(err_test, 3), \n",
    "     '\\nClassification error on Traindata:\\n', np.round(err_train, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting classification error on the test set is $22.4\\%$ of the test cases are classified correctly. The confusion matrix shows that the error is similar in both classes and that there is a slight imbalance between the classes. \n",
    "\n",
    "Compared to that, the error on the training set is smaller namely $0\\%$. This error can be made arbitrarily small by further splitting the regions in the tree until each node only contains one observation. Then the training error will be zero. \n",
    "\n",
    "If we allow very small terminal nodes, then the training error can be shrinked to $0$. In this case, however, the tree has a very high variance and the performance on the test set is bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
