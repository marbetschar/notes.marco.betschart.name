{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Example 5.1"
   ],
   "id": "2fe89fb7e0f29465"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit a multiple logistic regression model to the **Default** data set using **balance**, **income**, and **student** as predictor variables. Note that the latter is a *qualitative* predictor with levels **Yes** and **No**. In order to use it in the regession model, we define a *dummy variable* with value $1$ if **student=Yes** and $0$ if **student=No**.\n"
   ],
   "id": "8ce2b541cfd684e3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:18:38.576477Z",
     "start_time": "2025-10-20T14:18:38.558817Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./data/Default.csv', sep=';')\n",
    "\n",
    "# Add a numerical column for default\n",
    "df = df.join(pd.get_dummies(df[['default', 'student']], \n",
    "                            prefix={'default': 'default', \n",
    "                                    'student': 'student'},\n",
    "                            drop_first=True))\n",
    "# Set ramdom seed\n",
    "np.random.seed(1)\n",
    "# Index of Yes:\n",
    "i_yes = df.loc[df['default_Yes'] == 1, :].index\n",
    "\n",
    "# Random set of No:\n",
    "i_no = df.loc[df['default_Yes'] == 0, :].index\n",
    "i_no = np.random.choice(i_no, replace=False, size=333)\n",
    "\n",
    "# Fit Linear Model on downsampled data\n",
    "i_ds = np.concatenate((i_no, i_yes))\n",
    "x_ds = df.iloc[i_ds][['balance', 'income', 'student_Yes']]\n",
    "y_ds = df.iloc[i_ds]['default_Yes']\n",
    "\n",
    "# Model using statsmodels.api\n",
    "x_sm = sm.add_constant(x_ds.astype('float'))\n",
    "model_sm = sm.GLM(y_ds, x_sm, family=sm.families.Binomial())\n",
    "model_sm = model_sm.fit()\n",
    "\n",
    "print(model_sm.summary())"
   ],
   "id": "87fb2024a91c03c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            default_Yes   No. Observations:                  666\n",
      "Model:                            GLM   Df Residuals:                      662\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -186.21\n",
      "Date:                Mon, 20 Oct 2025   Deviance:                       372.42\n",
      "Time:                        16:18:38   Pearson chi2:                     571.\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.5627\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -7.1303      0.869     -8.205      0.000      -8.833      -5.427\n",
      "balance         0.0060      0.000     12.928      0.000       0.005       0.007\n",
      "income      -1.454e-05    1.6e-05     -0.909      0.363   -4.59e-05    1.68e-05\n",
      "student_Yes    -0.8278      0.465     -1.780      0.075      -1.739       0.084\n",
      "===============================================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:18:38.597009Z",
     "start_time": "2025-10-20T14:18:38.585714Z"
    }
   },
   "source": [
    "# Predict training data\n",
    "x_pred = x_sm\n",
    "y_pred = model_sm.predict(x_pred)\n",
    "\n",
    "# Round to 0 or 1\n",
    "y_pred = y_pred.round()\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion = pd.DataFrame({'predicted': y_pred,\n",
    "                          'true': y_ds})\n",
    "confusion = pd.crosstab(confusion.predicted, confusion.true, \n",
    "                        margins=True, margins_name=\"Sum\")\n",
    "\n",
    "print(confusion)"
   ],
   "id": "18582b01e9662a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true       False  True  Sum\n",
      "predicted                  \n",
      "0.0          293    36  329\n",
      "1.0           40   297  337\n",
      "Sum          333   333  666\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:18:40.245229Z",
     "start_time": "2025-10-20T14:18:38.605026Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Model using sklearn\n",
    "model_sk = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "\n",
    "# Calculate cross validation scores:\n",
    "scores = cross_val_score(model_sk, x_ds, y_ds, cv=5)\n",
    "print(np.mean(scores))"
   ],
   "id": "53a93a9f5308e0c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8827965435978005\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we find that the predictors **balance** and **student** are significant, i.e. they contribute substantially to the model for **default**. The coefficient of **student** is negative, i.e. the student status means a *decrease* in probability for default for a fixed value of **balance** and **income**.\n",
    "\n",
    "Further we find a cross-validated score of 0.8828, which amounts to say that the model classifies correctly 88.28% of the cases. This is not much an increase compared with the single logistic regression model. Also the confusion matrix is very similar to the simple regression case. \n",
    "\n",
    "We will now use the coefficients above in order to predict the probability for default for new observations. For example, if a student has a credit card bill of CHF 1500 and an income of CHF 40000, so the estimated probability for **default** is\n",
    "\\begin{equation}\n",
    "\\hat{p}(1500,40,1)\n",
    "=\\dfrac{e^{-6.679+0.00529\\cdot 1500 -0.0043\\cdot 40-0.6468\\cdot 1}}{1+e^{-6.679+0.00529\\cdot 1500-0.0043\\cdot 40-0.6468\\cdot 1}}\n",
    "=0.564\n",
    "\\end{equation}\n",
    "\n",
    "For a non-student with the same balance and income the estimated probability for default is\n",
    "\\begin{equation}\n",
    "\\hat{p}(1500,40,0)\n",
    "=\\dfrac{e^{-6.679+0.00529\\cdot 1500-0.0043\\cdot 40-0.6468\\cdot 0}}{1+e^{-6.679+0.00529\\cdot 1500-0.0043\\cdot 40-0.6468\\cdot 0}}\n",
    "=0.747\n",
    "\\end{equation}\n",
    "The coefficient for **income** is multiplied by $1000$ for lucidity. Thus we insert $40$ instead of $40000$ into the model. \n"
   ],
   "id": "48f6405071adaefb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
