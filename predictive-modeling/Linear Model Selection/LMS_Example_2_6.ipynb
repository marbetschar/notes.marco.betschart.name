{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model Selection Example 2.6\n",
    "\n",
    "The right-hand panel displays the BIC for the **Credit** data set. For instance, the BIC values result from subtracting the BIC of the null model. \n",
    "\n",
    "Based on the BIC values displayed in the **Python**-output, we conclude that the best model produced by forward stepwise selection contains five predictor variables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Python**-output in the previous example shows that the best model produced by forward stepwise selection and containing five predictors is given by\n",
    "\\begin{align*}\n",
    " balance\n",
    "&=\\beta_{0}+\\beta_{1}\\cdot income +\\beta_{2}\\cdot limit +\\beta_{3}\\cdot rating +\\beta_{4}\\cdot cards \\\\\n",
    "&\\quad+\\beta_{5}\\cdot student +epsilon\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Predictors and corresponding BIC:\n",
      "                Best_Pred          BIC\n",
      "0                 Rating  5502.764477\n",
      "1                 Income  5224.531479\n",
      "2           Student__Yes  4865.352851\n",
      "3                  Limit  4852.481331\n",
      "4                  Cards  4841.615607\n",
      "5                    Age  4842.979215\n",
      "6         Gender__Female  4847.832276\n",
      "7             Unnamed: 0  4852.927218\n",
      "8       Ethnicity__Asian  4858.201340\n",
      "9           Married__Yes  4863.468707\n",
      "10  Ethnicity__Caucasian  4868.833498\n",
      "11             Education  4874.337112 \n",
      "\n",
      "The best model thus contains 5  predictors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from LMS_def import *\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./data/Credit.csv')\n",
    "\n",
    "# Convert Categorical variables\n",
    "df = pd.get_dummies(data=df, drop_first=True, \n",
    "                    prefix=('Gender_', 'Student_', \n",
    "                            'Married_', 'Ethnicity_'))\n",
    "\n",
    "x_full = df.drop(columns='Balance')\n",
    "y = df['Balance']\n",
    "\n",
    "results = pd.DataFrame(data={'Best_Pred': [], 'BIC':[]})\n",
    "\n",
    "# Define the empty predictor\n",
    "x0 = [np.zeros(len(y))]\n",
    "\n",
    "x = x0\n",
    "x_red = x_full.copy()\n",
    "\n",
    "for i in range(x_full.shape[1]):\n",
    "    results_i, best_i = add_one(x_red, x, y, scoreby='BIC')\n",
    "    \n",
    "    # Update the empty predictor with the best predictor\n",
    "    x = np.concatenate((x, [df[best_i]]))\n",
    "\n",
    "    # Remove the chosen predictor from the list of options\n",
    "    x_red = x_red.drop(columns=best_i)\n",
    "\n",
    "    # Save results \n",
    "    results.loc[i, 'Best_Pred'] = best_i\n",
    "    results.loc[i, 'BIC'] = results_i['BIC'].min()\n",
    "    \n",
    "print('Best Predictors and corresponding BIC:\\n', results, \n",
    "      '\\n\\nThe best model thus contains', \n",
    "      results['BIC'].argmin() + 1, ' predictors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to identify the best model  by *backward stepwise selection*, then we can use the same procedure as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst Predictors and corresponding BIC:\n",
      "               Worst_Pred          BIC\n",
      "0              Education  4868.833498\n",
      "1   Ethnicity__Caucasian  4863.468707\n",
      "2           Married__Yes  4858.201340\n",
      "3       Ethnicity__Asian  4852.927218\n",
      "4             Unnamed: 0  4847.832276\n",
      "5         Gender__Female  4842.979215\n",
      "6                    Age  4841.615607\n",
      "7                 Rating  4840.658660\n",
      "8                  Cards  4873.759072\n",
      "9           Student__Yes  5237.176925\n",
      "10                Income  5507.965562\n",
      "11                 Limit  6044.702777 \n",
      "\n",
      "The best model thus contains 5  predictors\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(data={'Worst_Pred': [], 'BIC':[]})\n",
    "\n",
    "# Define the full predictor\n",
    "x = x_full.copy()\n",
    "\n",
    "for i in range(x_full.shape[1]):\n",
    "    results_i, worst_i = drop_one(x, y, scoreby='BIC')\n",
    "    \n",
    "    # Update the empty predictor with the best predictor\n",
    "    x = x.drop(columns=worst_i)\n",
    "\n",
    "    # Save results \n",
    "    results.loc[i, 'Worst_Pred'] = worst_i\n",
    "    results.loc[i, 'BIC'] = results_i['BIC'].min()\n",
    "    \n",
    "print('Worst Predictors and corresponding BIC:\\n', results, \n",
    "      '\\n\\nThe best model thus contains', \n",
    "      x_full.shape[1] - results['BIC'].argmin(), ' predictors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
